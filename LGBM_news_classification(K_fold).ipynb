{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3152536,"sourceType":"datasetVersion","datasetId":1918386}],"dockerImageVersionId":30157,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import RidgeClassifier, LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nfrom lightgbm import LGBMClassifier\nimport pandas as pd\nimport lightgbm as lgb","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DEBUG = True","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#读取数据集\ntrain_df = pd.read_csv('/kaggle/input/news01/train_set.csv',sep='\\t')\ntest_df = pd.read_csv('/kaggle/input/news01/test_a.csv',sep='\\t')\nif DEBUG:\n    train_df = train_df[:100]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Tfidf编码\ntfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=1000).fit(train_df['text'].iloc[:].values)\ntrain_tfidf = tfidf.transform(train_df['text'].iloc[:].values)\ntest_tfidf = tfidf.transform(test_df['text'].iloc[:].values)\nprint('Finish Tfidf')\n\n#Lgb\n# clf = RidgeClassifier()\n# clf = LogisticRegression()\nclf = LGBMClassifier()\nclf.fit(train_tfidf, train_df['label'].iloc[:].values)\nprint('Finish Lgb')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"res = pd.DataFrame()\nres['label'] = clf.predict(test_tfidf)\nres.to_csv('base_submission.csv', index=None)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_fold = 5\nlabel = 'label'\n#lgb参数\nlgb_params = {\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"multiclass\",\n    'metric': 'multi_error',\n    \"num_class\": 14,\n    \"learning_rate\": 0.01,\n    \"max_depth\": -1,\n    \"num_leaves\": 15,\n    \"feature_fraction\": 1,\n    \"bagging_fraction\": 1,     \n    'min_data_in_leaf': 100,  \n    'bagging_freq': 6, \n    \"nthread\":-1,\n    \"verbose\":-1,\n    \n}\ny_val = np.zeros((train_tfidf.shape[0],14))\ny_test = np.zeros((test_tfidf.shape[0],14))\n\nskf = StratifiedKFold(n_splits=n_fold,shuffle=True,random_state=42)\nfor train_index,valid_index in skf.split(train_df,train_df[label]):\n    \n    x_train,x_valid,y_train,y_valid = train_tfidf[train_index],train_tfidf[valid_index],train_df[label].iloc[train_index],train_df[label].iloc[valid_index]\n\n    train_data = lgb.Dataset(x_train,label=y_train)\n    valid_data = lgb.Dataset(x_valid,label=y_valid)\n    \n    model = lgb.train(lgb_params,train_data,valid_sets=[train_data,valid_data],num_boost_round=10000,verbose_eval=50, early_stopping_rounds = 50)\n    \n    y_val[valid_index] = model.predict(x_valid)\n    y_test += np.array(model.predict(test_tfidf)/n_fold)\n\ncv_score = f1_score(np.argmax(y_val,axis=1),train_df[label].values, average='macro')\nprint(f'local cv: {cv_score}')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"res = pd.DataFrame()\nres['label'] = np.argmax(y_test,axis=1)\nres.to_csv('c_submission.csv', index=None)","metadata":{},"outputs":[],"execution_count":null}]}