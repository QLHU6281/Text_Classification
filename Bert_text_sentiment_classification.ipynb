{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:17:14.527274Z","iopub.execute_input":"2024-11-22T06:17:14.527600Z","iopub.status.idle":"2024-11-22T06:17:15.540362Z","shell.execute_reply.started":"2024-11-22T06:17:14.527564Z","shell.execute_reply":"2024-11-22T06:17:15.539349Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:17:47.420224Z","iopub.execute_input":"2024-11-22T06:17:47.420672Z","iopub.status.idle":"2024-11-22T06:17:52.754282Z","shell.execute_reply.started":"2024-11-22T06:17:47.420638Z","shell.execute_reply":"2024-11-22T06:17:52.753514Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def load_imdb_data(data_file):\n    df = pd.read_csv(data_file)\n    texts = df['review'].tolist()\n    labels = [1 if sentiment == \"positive\" else 0 for sentiment in df['sentiment'].tolist()]\n    return texts, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:17:57.237098Z","iopub.execute_input":"2024-11-22T06:17:57.238379Z","iopub.status.idle":"2024-11-22T06:17:57.243423Z","shell.execute_reply.started":"2024-11-22T06:17:57.238326Z","shell.execute_reply":"2024-11-22T06:17:57.242568Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data_file = \"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\"\ntexts, labels = load_imdb_data(data_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:18:04.173980Z","iopub.execute_input":"2024-11-22T06:18:04.174337Z","iopub.status.idle":"2024-11-22T06:18:05.635120Z","shell.execute_reply.started":"2024-11-22T06:18:04.174305Z","shell.execute_reply":"2024-11-22T06:18:05.634259Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class TextClassificationDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:18:08.998235Z","iopub.execute_input":"2024-11-22T06:18:08.998622Z","iopub.status.idle":"2024-11-22T06:18:09.004396Z","shell.execute_reply.started":"2024-11-22T06:18:08.998586Z","shell.execute_reply":"2024-11-22T06:18:09.003478Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class BERTClassifier(nn.Module):\n    def __init__(self, bert_model_name, num_classes):\n        super(BERTClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        self.dropout = nn.Dropout(0.1)\n        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        x = self.dropout(pooled_output)\n        logits = self.fc(x)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:18:12.413827Z","iopub.execute_input":"2024-11-22T06:18:12.414546Z","iopub.status.idle":"2024-11-22T06:18:12.420231Z","shell.execute_reply.started":"2024-11-22T06:18:12.414498Z","shell.execute_reply":"2024-11-22T06:18:12.419192Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def train(model, data_loader, optimizer, scheduler, device):\n    model.train()\n    for batch in data_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = nn.CrossEntropyLoss()(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:18:16.717670Z","iopub.execute_input":"2024-11-22T06:18:16.718062Z","iopub.status.idle":"2024-11-22T06:18:16.724159Z","shell.execute_reply.started":"2024-11-22T06:18:16.718030Z","shell.execute_reply":"2024-11-22T06:18:16.723136Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def evaluate(model, data_loader, device):\n    model.eval()\n    predictions = []\n    actual_labels = []\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            _, preds = torch.max(outputs, dim=1)\n            predictions.extend(preds.cpu().tolist())\n            actual_labels.extend(labels.cpu().tolist())\n    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:18:20.031271Z","iopub.execute_input":"2024-11-22T06:18:20.031762Z","iopub.status.idle":"2024-11-22T06:18:20.038128Z","shell.execute_reply.started":"2024-11-22T06:18:20.031729Z","shell.execute_reply":"2024-11-22T06:18:20.037008Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def predict_sentiment(text, model, tokenizer, device, max_length=128):\n    model.eval()\n    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        preds = torch.max(outputs, dim=1)\n    return \"positive\" if preds.item() == 1 else \"negative\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:18:23.221448Z","iopub.execute_input":"2024-11-22T06:18:23.222418Z","iopub.status.idle":"2024-11-22T06:18:23.229584Z","shell.execute_reply.started":"2024-11-22T06:18:23.222372Z","shell.execute_reply":"2024-11-22T06:18:23.228511Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":" bert_model_name = 'bert-base-uncased'\n num_classes = 2 \n max_length = 128\n batch_size = 8\n num_epochs = 10\n learning_rate = 2e-5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:18:25.756667Z","iopub.execute_input":"2024-11-22T06:18:25.757089Z","iopub.status.idle":"2024-11-22T06:18:25.762180Z","shell.execute_reply.started":"2024-11-22T06:18:25.757058Z","shell.execute_reply":"2024-11-22T06:18:25.760933Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.15, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:18:28.629290Z","iopub.execute_input":"2024-11-22T06:18:28.629691Z","iopub.status.idle":"2024-11-22T06:18:28.658199Z","shell.execute_reply.started":"2024-11-22T06:18:28.629653Z","shell.execute_reply":"2024-11-22T06:18:28.657283Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"    tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n    train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n    val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = BERTClassifier(bert_model_name, num_classes).to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n    total_steps = len(train_dataloader) * num_epochs\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:18:30.847991Z","iopub.execute_input":"2024-11-22T06:18:30.848328Z","iopub.status.idle":"2024-11-22T06:18:35.300427Z","shell.execute_reply.started":"2024-11-22T06:18:30.848295Z","shell.execute_reply":"2024-11-22T06:18:35.299593Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f69c89bcc204b4db4c6c5c72b8cd2e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0d3b2dfae2e45aaa15176199c001b6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96f36c78ecc044649e93610c9c383727"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e3b35e6f1e24b9cbffe799f5b35dcc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6673efbcc7544c699c4ebe53cbf3b77"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"for epoch in range(num_epochs):\n        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n        train(model, train_dataloader, optimizer, scheduler, device)\n        accuracy, report = evaluate(model, val_dataloader, device)\n        print(f\"Validation Accuracy: {accuracy:.4f}\")\n        print(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T06:18:42.224045Z","iopub.execute_input":"2024-11-22T06:18:42.224405Z","iopub.status.idle":"2024-11-22T09:52:26.258780Z","shell.execute_reply.started":"2024-11-22T06:18:42.224374Z","shell.execute_reply":"2024-11-22T09:52:26.257706Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\nValidation Accuracy: 0.8925\n              precision    recall  f1-score   support\n\n           0       0.91      0.87      0.89      3708\n           1       0.88      0.91      0.90      3792\n\n    accuracy                           0.89      7500\n   macro avg       0.89      0.89      0.89      7500\nweighted avg       0.89      0.89      0.89      7500\n\nEpoch 2/10\nValidation Accuracy: 0.8940\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.89      3708\n           1       0.91      0.88      0.89      3792\n\n    accuracy                           0.89      7500\n   macro avg       0.89      0.89      0.89      7500\nweighted avg       0.89      0.89      0.89      7500\n\nEpoch 3/10\nValidation Accuracy: 0.8980\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.89      3708\n           1       0.88      0.92      0.90      3792\n\n    accuracy                           0.90      7500\n   macro avg       0.90      0.90      0.90      7500\nweighted avg       0.90      0.90      0.90      7500\n\nEpoch 4/10\nValidation Accuracy: 0.8967\n              precision    recall  f1-score   support\n\n           0       0.92      0.87      0.89      3708\n           1       0.88      0.92      0.90      3792\n\n    accuracy                           0.90      7500\n   macro avg       0.90      0.90      0.90      7500\nweighted avg       0.90      0.90      0.90      7500\n\nEpoch 5/10\nValidation Accuracy: 0.8960\n              precision    recall  f1-score   support\n\n           0       0.89      0.90      0.90      3708\n           1       0.90      0.89      0.90      3792\n\n    accuracy                           0.90      7500\n   macro avg       0.90      0.90      0.90      7500\nweighted avg       0.90      0.90      0.90      7500\n\nEpoch 6/10\nValidation Accuracy: 0.8996\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.90      3708\n           1       0.90      0.91      0.90      3792\n\n    accuracy                           0.90      7500\n   macro avg       0.90      0.90      0.90      7500\nweighted avg       0.90      0.90      0.90      7500\n\nEpoch 7/10\nValidation Accuracy: 0.8968\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.89      3708\n           1       0.89      0.91      0.90      3792\n\n    accuracy                           0.90      7500\n   macro avg       0.90      0.90      0.90      7500\nweighted avg       0.90      0.90      0.90      7500\n\nEpoch 8/10\nValidation Accuracy: 0.8999\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.90      3708\n           1       0.89      0.92      0.90      3792\n\n    accuracy                           0.90      7500\n   macro avg       0.90      0.90      0.90      7500\nweighted avg       0.90      0.90      0.90      7500\n\nEpoch 9/10\nValidation Accuracy: 0.8977\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.90      3708\n           1       0.89      0.90      0.90      3792\n\n    accuracy                           0.90      7500\n   macro avg       0.90      0.90      0.90      7500\nweighted avg       0.90      0.90      0.90      7500\n\nEpoch 10/10\nValidation Accuracy: 0.8972\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.90      3708\n           1       0.89      0.90      0.90      3792\n\n    accuracy                           0.90      7500\n   macro avg       0.90      0.90      0.90      7500\nweighted avg       0.90      0.90      0.90      7500\n\n","output_type":"stream"}],"execution_count":13}]}